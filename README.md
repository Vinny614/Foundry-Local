# Foundry Local + MCP + Phi: Offline AI Demo on Azure

A complete, reproducible demonstration of **Foundry Local** with **Phi model** running fully offline on a single Windows Azure VM, using **MCP (Model Context Protocol) tools** for local data analytics.

## ğŸ¯ What This Demo Does

- âœ… Deploys Azure infrastructure using **Bicep**
- âœ… Installs **Foundry Local** and caches a **Phi model** on Windows Server 2022
- âœ… Sets up a **SQLite database** with sample sales data
- âœ… Runs a **local MCP server** exposing read-only SQL tools
- âœ… Provides a **Python agent** that combines Phi + MCP for natural language data queries
- âœ… Proves **complete offline operation** (no internet after setup)
- âœ… Includes **security lockdown** (NSG + Windows Firewall)

## ğŸ“ Repository Structure

```
â”œâ”€â”€ infra/bicep/          # Bicep infrastructure modules
â”œâ”€â”€ vm/bootstrap/         # PowerShell setup scripts for VM
â”œâ”€â”€ app/                  # Python agent application
â”œâ”€â”€ scripts/              # Helper utilities
â””â”€â”€ docs/                 # Full documentation
```

## ğŸš€ Quick Start

1. **Prerequisites**: Azure CLI, Azure subscription, your public IP
2. **Deploy**: `cd infra/bicep && ./deploy.sh <resource-group-name>`
3. **RDP to VM**: Use public IP from deployment outputs
4. **Bootstrap VM**: Run scripts in `vm/bootstrap/` (as Administrator)
5. **Test Agent**: `python C:\FoundryDemo\agent\agent.py`
6. **Go Offline**: Run `lock_down_offline.ps1`
7. **Verify**: Run `verify_offline.ps1` and test agent again

## ğŸ“š Full Documentation

See [docs/README.md](docs/README.md) for:
- Architecture diagrams
- Step-by-step deployment guide
- Security configuration
- Troubleshooting
- Cost estimates
- Testing procedures
- Microsoft Learn references

## ğŸ”— Key Technologies

- **[Foundry Local](https://learn.microsoft.com/en-us/azure/ai-foundry/foundry-local/)** - Microsoft's on-device AI inference
- **[Phi Models](https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/)** - Small Language Models from Microsoft
- **[MCP](https://spec.modelcontextprotocol.io/)** - Model Context Protocol for tool calling
- **[Azure Bicep](https://learn.microsoft.com/en-us/azure/azure-resource-manager/bicep/)** - Infrastructure as Code

## ğŸ“ What You'll Learn

- How to run AI models completely offline after initial caching
- Building local tool calling systems with MCP
- Bicep infrastructure patterns for AI workloads
- Security-first Azure VM configuration
- PowerShell automation for Windows Server setup

## ğŸ“Š Architecture

```
User Question â†’ [Foundry Local Phi Model] â†’ Determines tool need
                        â†“
        [MCP Server] â†’ [SQLite Database] â†’ Query results
                        â†“
[Foundry Local] â†’ Natural language response
```

All running on a single Azure VM, completely offline after setup.

## ğŸ” Security

- RDP restricted to your IP only
- Foundry Local and MCP bound to localhost
- Windows Firewall blocks all outbound (after lockdown)
- Optional NSG egress deny
- No secrets in repository

## ğŸ§¹ Cleanup

```bash
az group delete --name <resource-group-name> --yes
```

## ğŸ“œ License

MIT License - See LICENSE file

---

**For complete documentation, see [docs/README.md](docs/README.md)**